{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import json\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the CSV file into a Pandas dataframe\n",
    "df = pd.read_csv(''data/output.csv'')\n",
    "\n",
    "# Rename the \"sypnopsis\" column to \"synopsis\"\n",
    "df = df.rename(columns={'sypnopsis': 'synopsis'})\n",
    "\n",
    "# Drop Duplicate names\n",
    "df.drop_duplicates(subset='Name', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_id_to_index = {anime_id:index for index, anime_id in enumerate(df['MAL_ID'])}\n",
    "anime_name_to_id = {name:mid for name, mid in zip(df['Name'], df['MAL_ID'])}\n",
    "anime_id_to_name = {v:k for k,v in anime_name_to_id.items()}\n",
    "anime_name_to_index = {name:anime_id_to_index[anime_name_to_id[name]] for name in df['Name']}\n",
    "anime_index_to_name = {v:k for k,v in anime_name_to_index.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feats = 5000\n",
    "doc_by_vocab = np.empty([len(df), n_feats])\n",
    "\n",
    "def build_vectorizer(max_features, stop_words, max_df=0.8, min_df=10, norm='l2'):\n",
    "    \"\"\"Returns a TfidfVectorizer object with the above preprocessing properties.\n",
    "    \n",
    "    Note: This function may log a deprecation warning. This is normal, and you\n",
    "    can simply ignore it.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    max_features : int\n",
    "        Corresponds to 'max_features' parameter of the sklearn TfidfVectorizer \n",
    "        constructer.\n",
    "    stop_words : str\n",
    "        Corresponds to 'stop_words' parameter of the sklearn TfidfVectorizer constructer. \n",
    "    max_df : float\n",
    "        Corresponds to 'max_df' parameter of the sklearn TfidfVectorizer constructer. \n",
    "    min_df : float\n",
    "        Corresponds to 'min_df' parameter of the sklearn TfidfVectorizer constructer. \n",
    "    norm : str\n",
    "        Corresponds to 'norm' parameter of the sklearn TfidfVectorizer constructer. \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    TfidfVectorizer\n",
    "        A TfidfVectorizer object with the given parameters as its preprocessing properties.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    vectorizer = TfidfVectorizer(max_features = max_features, stop_words=stop_words, max_df=max_df, min_df=min_df, norm=norm)\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = build_vectorizer(n_feats, \"english\")\n",
    "doc_by_vocab = tfidf_vec.fit_transform(df['synopsis'].values.astype('U')).toarray()\n",
    "index_to_vocab = {i:v for i, v in enumerate(tfidf_vec.get_feature_names())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.39281937 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_by_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim(mov1, mov2, input_doc_mat, input_movie_name_to_index):\n",
    "    \"\"\"Returns a float giving the cosine similarity of \n",
    "       the two movie transcripts.\n",
    "    \n",
    "    Params: {mov1 (str): Name of the first movie.\n",
    "             mov2 (str): Name of the second movie.\n",
    "             input_doc_mat (numpy.ndarray): Term-document matrix of movie transcripts, where \n",
    "                    each row represents a document (movie transcript) and each column represents a term.\n",
    "             movie_name_to_index (dict): Dictionary that maps movie names to the corresponding row index \n",
    "                    in the term-document matrix.}\n",
    "    Returns: Float (Cosine similarity of the two movie transcripts.)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    index1 = input_movie_name_to_index[mov1]\n",
    "    index2 = input_movie_name_to_index[mov2]\n",
    "    arr1 = input_doc_mat[index1]\n",
    "    arr2 = input_doc_mat[index2]\n",
    "    numerator = np.dot(arr1,arr2)\n",
    "    denomenator = LA.norm(arr1)*LA.norm(arr2)\n",
    "    \n",
    "    return numerator/denomenator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = get_sim('Trigun', 'Cowboy Bebop', doc_by_vocab, anime_name_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036221562027022834\n"
     ]
    }
   ],
   "source": [
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_movie_sims_cos(n_mov, movie_index_to_name, input_doc_mat, movie_name_to_index, input_get_sim_method):\n",
    "    \"\"\"Returns a movie_sims matrix of size (num_movies,num_movies) where for (i,j):\n",
    "        [i,j] should be the cosine similarity between the movie with index i and the movie with index j\n",
    "        \n",
    "    Note: You should set values on the diagonal to 1\n",
    "    to indicate that all movies are trivially perfectly similar to themselves.\n",
    "    \n",
    "    Params: {n_mov: Integer, the number of movies\n",
    "             movie_index_to_name: Dictionary, a dictionary that maps movie index to name\n",
    "             input_doc_mat: Numpy Array, a numpy array that represents the document-term matrix\n",
    "             movie_name_to_index: Dictionary, a dictionary that maps movie names to index\n",
    "             input_get_sim_method: Function, a function to compute cosine similarity}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    movie_sims_matrix = np.zeros((n_mov, n_mov))\n",
    "    \n",
    "    for i in range(0, n_mov):\n",
    "        for j in range(0, n_mov):\n",
    "            sim_score = input_get_sim_method(movie_index_to_name[i], movie_index_to_name[j], input_doc_mat, movie_name_to_index)\n",
    "            movie_sims_matrix[i][j] = sim_score\n",
    "    \n",
    "    return movie_sims_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sims_cos = build_movie_sims_cos(1000, anime_index_to_name, doc_by_vocab, anime_name_to_index, get_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_movie_sims_jac(n_mov, input_data):\n",
    "    \"\"\"Returns a movie_sims_jac matrix of size (num_movies,num_movies) where for (i,j) :\n",
    "        [i,j] should be the jaccard similarity between the category sets for movies i and j\n",
    "        such that movie_sims_jac[i,j] = movie_sims_jac[j,i]. \n",
    "        \n",
    "    Note: \n",
    "        Movies sometimes contain *duplicate* categories! You should only count a category once\n",
    "        \n",
    "        A movie should have a jaccard similarity of 1.0 with itself.\n",
    "    \n",
    "    Params: {n_mov: Integer, the number of movies,\n",
    "            input_data: List<Dictionary>, a list of dictionaries where each dictionary \n",
    "                     represents the movie_script_data including the script and the metadata of each movie script}\n",
    "    Returns: Numpy Array \n",
    "    \"\"\"\n",
    "    genre_sims = np.zeros((n_mov, n_mov))\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    for i in range (0, n_mov):\n",
    "        for j in range (0, n_mov):\n",
    "            Al = input_data[i].split(',')\n",
    "            Al = [s.strip() for s in Al]\n",
    "            A = set(Al)\n",
    "            \n",
    "            Bl = input_data[j].split(',')\n",
    "            Bl = [s.strip() for s in Bl]\n",
    "            B = set(Bl)\n",
    "            if(len(A.union(B)) > 0):\n",
    "                jac_sim = len(A.intersection(B))/len(A.union(B))\n",
    "            genre_sims[i][j] = jac_sim\n",
    "            genre_sims[j][i] = jac_sim\n",
    "            \n",
    "    \n",
    "    return genre_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_sims_jac = build_movie_sims_jac(1000,df['Genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = movie_sims_jac[anime_name_to_index['Cowboy Bebop'] , anime_name_to_index['Cowboy Bebop']]\n",
    "test2 = movie_sims_jac[anime_name_to_index['Cowboy Bebop'] , anime_name_to_index['Cowboy Bebop: Tengoku no Tobira']]\n",
    "test3 = movie_sims_jac[anime_name_to_index['Hungry Heart: Wild Striker'] , anime_name_to_index['Cowboy Bebop: Tengoku no Tobira']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.5714285714285714\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(test1) #equals 1\n",
    "print(test2)\n",
    "print(test3) #equal 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_movies(mov, matrix):\n",
    "    \"\"\"\n",
    "    Return sorted rankings (most to least similar) of movies as \n",
    "    a list of two-element tuples, where the first element is the \n",
    "    movie name and the second element is the similarity score\n",
    "    \n",
    "    Params: {mov: String,\n",
    "             matrix: np.ndarray}\n",
    "    Returns: List<Tuple>\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get movie index from movie name\n",
    "    mov_idx = anime_name_to_index[mov]\n",
    "    \n",
    "    # Get list of similarity scores for movie\n",
    "    score_lst = matrix[mov_idx]\n",
    "    mov_score_lst = [(anime_index_to_name[i], s) for i,s in enumerate(score_lst)]\n",
    "    \n",
    "    # Do not account for movie itself in ranking\n",
    "    mov_score_lst = mov_score_lst[:mov_idx] + mov_score_lst[mov_idx+1:]\n",
    "    \n",
    "    # Sort rankings by score\n",
    "    mov_score_lst = sorted(mov_score_lst, key=lambda x: -x[1])\n",
    "    \n",
    "    return mov_score_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_jac_sim(anime, genres, arr):\n",
    "    # Get movie index from movie name\n",
    "    anime_idx = anime_name_to_index[anime]\n",
    "    score_lst = []\n",
    "    \n",
    "    for i,tup in enumerate(arr):\n",
    "        \n",
    "        A = set(genres)\n",
    "        l = df['Genres'][anime_name_to_index[tup[0]]].split(',')\n",
    "        l = [s.strip() for s in l]\n",
    "        B = set(l)\n",
    "        jac_sim = 0\n",
    "        if(len(A.union(B)) > 0):\n",
    "            jac_sim = len(A.intersection(B))/len(A.union(B))        \n",
    "        arr[i] = (tup[0], tup[1]*jac_sim)\n",
    "        \n",
    "    arr = sorted(arr, key=lambda x: -x[1])\n",
    "\n",
    "    return arr\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_ratings(arr):\n",
    "    for i, tup in enumerate(arr):\n",
    "        score = df['Score'][i]\n",
    "        score = 'hi'\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except:\n",
    "            score = 5\n",
    "        arr[i] = (tup[0], tup[1]*score)\n",
    "        \n",
    "    arr = sorted(arr, key=lambda x: -x[1])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.402 Cowboy Bebop: Tengoku no Tobira\n",
      "0.188 Youjuu Toshi\n",
      "0.167 Uchuu Kaizoku Captain Herlock\n",
      "0.165 One: Kagayaku Kisetsu e\n",
      "0.159 Noir\n",
      "0.143 WeiÃŸ Kreuz OVA\n",
      "0.131 Fullmetal Alchemist\n",
      "0.130 Seihou Bukyou Outlaw Star\n",
      "0.127 Mobile Suit Gundam SEED\n",
      "0.121 Uchuu no Stellvia\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "## Recommendation for Cowboy Bepop\n",
    "test_anime = 'Cowboy Bebop'\n",
    "initial_ranking = get_ranked_movies(test_anime , movie_sims_cos)\n",
    "ranking_jac = multiply_jac_sim(test_anime, [\"Action\", \"Drama\"] ,initial_ranking)\n",
    "ranking_score = multiply_ratings(ranking_jac)\n",
    "\n",
    "for (anime, score) in ranking_score[:10]:\n",
    "        print(\"%.3f %s\" % (score, anime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do:\n",
    "\n",
    "##### Changes movie -> Anime\n",
    "##### Only on 1000\n",
    "##### Can we use global variables?\n",
    "##### Tests? \n",
    "##### Anime has no Transcript?\n",
    "##### I sorted after each adjustment so I could look at it, we could only do it once tho in the final product\n",
    "#####  Relevancy score are low rn because of the transcript matching, if they get higher we may want to log ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
